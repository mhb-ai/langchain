{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "-zuGbwN2eW21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htpYLToPOw2v"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "O4ezBdgiUubO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "AB-iUkSw4JrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV\n",
        "df = pd.read_csv(\"dataset2.csv\")\n",
        "\n",
        "# Quick look at the data\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "_-jZWPvZXcCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine question and answer into one field for embedding\n",
        "df[\"content\"] = df[\"question\"] + \"\\n\\n\" + df[\"answer\"]\n",
        "\n",
        "# Optional: drop rows with missing values\n",
        "df = df.dropna(subset=[\"content\"])"
      ],
      "metadata": {
        "id": "LA3AoVSTXiFM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning\n",
        "df[\"content\"] = df[\"content\"].str.replace(r\"\\[\\{\\(/NL/\\)\\}\\]\", \"\\n\", regex=True)\n",
        "print(df[\"content\"].iloc[0])\n"
      ],
      "metadata": {
        "id": "B0IEh01MXrHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain chromadb langchain-chroma openai tiktoken\n"
      ],
      "metadata": {
        "id": "tMY7D0r9ZPDY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "id": "zsboDnSEkN1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4_X8W8cf5yr",
        "outputId": "8c26f7f6-b98d-4679-e332-88c06e2467b4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for OpenAI: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ],
      "metadata": {
        "id": "hMlBDZP2aBYg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make ChromaDB"
      ],
      "metadata": {
        "id": "qDMQYP1S4Wz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Convert content into LangChain Documents\n",
        "documents = [Document(page_content=row) for row in df[\"content\"].tolist()]\n",
        "\n",
        "# 2. Create embedding function\n",
        "embedding_function = OpenAIEmbeddings()\n",
        "\n",
        "# 3. Create Chroma vectorstore\n",
        "# Break into batches\n",
        "batch_size = 200  # Keep this conservative to avoid hitting TPM\n",
        "vectorstore = None\n",
        "persist_dir = \"chroma_store\"\n",
        "\n",
        "for i in range(0, len(documents), batch_size):\n",
        "    batch_docs = documents[i:i+batch_size]\n",
        "\n",
        "    if vectorstore is None:\n",
        "        # Use the first batch to create a persistent Chroma vectorstore\n",
        "        vectorstore = Chroma.from_documents(\n",
        "            documents=batch_docs,\n",
        "            embedding=embedding_function,\n",
        "            persist_directory=persist_dir\n",
        "        )\n",
        "    else:\n",
        "        # Add more batches\n",
        "        vectorstore.add_documents(batch_docs)\n",
        "\n",
        "    print(f\"Embedded batch {i//batch_size + 1}\")\n"
      ],
      "metadata": {
        "id": "d2WzwfIsd_I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load a saved chromadb\n",
        "\n",
        "vectorstore = Chroma(\n",
        "    persist_directory=\"chroma_store\",\n",
        "    embedding_function=embedding_function\n",
        ")"
      ],
      "metadata": {
        "id": "n2sYrwJJxApZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the Retriever"
      ],
      "metadata": {
        "id": "9YH4da4ul4KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"mmr\",  # or use \"similarity\" + score_threshold\n",
        "    search_kwargs={\n",
        "        \"k\": 2,\n",
        "        \"score_threshold\": 0.4  # optional: helps filter weak results\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "VRCoz8O1lv17"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a QA Chain with Retrieval"
      ],
      "metadata": {
        "id": "w9a1n9OpmGby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA, LLMChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n"
      ],
      "metadata": {
        "id": "SsKJTtvyl9vm"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\",      # This is required!\n",
        "    return_messages=True            # So chat format is preserved\n",
        ")"
      ],
      "metadata": {
        "id": "-tVzj1h4zHzO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\",\n",
        "    temperature=0.9,\n",
        "    streaming=True,\n",
        "    callbacks=[StreamingStdOutCallbackHandler()])\n",
        "\n",
        "# Create the QA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    memory=memory,\n",
        "    return_source_documents=False\n",
        ")"
      ],
      "metadata": {
        "id": "an2TndfumKYg"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Query ReWriter"
      ],
      "metadata": {
        "id": "kMsBizB8s5Xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Ask Questions!"
      ],
      "metadata": {
        "id": "9XKSYjtimgfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    query = input(\"\\nYou: \")\n",
        "    if query.lower() in [\"exit\", \"quit\"]:\n",
        "        break\n",
        "    print(\"Bot:\", end=\" \", flush=True)\n",
        "    qa_chain(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRnYPRlzmbgO",
        "outputId": "359d1288-bc84-462f-b0a1-d120673c6bd6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "You: Please summarize the pillars of Islam\n",
            "Bot: The pillars of Islam consist of five core beliefs and practices: \n",
            "\n",
            "1. **Belief (Shahadah)**: The declaration of faith, stating that there is no god but Allah, and that Muhammad is His messenger.\n",
            "2. **Prayers (Salaah)**: The performance of ritual prayers five times a day.\n",
            "3. **Obligatory Charity (Zakah)**: The giving of a fixed portion of one's wealth to those in need, typically calculated as 2.5% of savings.\n",
            "4. **Fasting (Sawm)**: The observance of fasting during the month of Ramadan, abstaining from food and drink from dawn until sunset.\n",
            "5. **Pilgrimage (Hajj)**: The journey to the holy city of Mecca, which is required of all Muslims who are able to undertake it at least once in their lifetime.\n",
            "You: Make a drawing of mosque\n",
            "Bot: I'm sorry, but I can't create drawings. However, I can provide a description of a mosque if you'd like!\n",
            "You: What is a mosque\n",
            "Bot: I don't know.\n",
            "You: Who is ALLAH?\n",
            "Bot: Allah is the Arabic word for \"one God\". He is not the God of Muslims only, but is considered the God of all creations, as He is their Creator and Sustainer.\n",
            "You: Do you know what is neural net\n",
            "Bot: I don't know.\n",
            "You: Thanks\n",
            "Bot: You're welcome! If you have any more questions, feel free to ask.\n",
            "You: Quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZpWMFfr30FRt"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}